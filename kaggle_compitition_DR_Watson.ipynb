{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/ctanejaaa/chandan-taneja-101917048-final?scriptVersionId=90581148\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"Kaggle Compitition- Contradictory, My Dear Watson. \nComparing two setences via tokenize each pair of sentences and doing word embedding over them.\nRank - 12 \nAccuracy =0.92","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n#inporting files from the folder\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n        \n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-16T18:52:52.661694Z","iopub.execute_input":"2022-03-16T18:52:52.661983Z","iopub.status.idle":"2022-03-16T18:52:52.670948Z","shell.execute_reply.started":"2022-03-16T18:52:52.661953Z","shell.execute_reply":"2022-03-16T18:52:52.670212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# importing bert tokenizer for pretrained model\n!pip install transformers\nfrom transformers import BertTokenizer, TFBertModel, TFAutoModel,AutoTokenizer\nimport matplotlib.pyplot as plt\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:52:54.209208Z","iopub.execute_input":"2022-03-16T18:52:54.209885Z","iopub.status.idle":"2022-03-16T18:53:02.185819Z","shell.execute_reply.started":"2022-03-16T18:52:54.209849Z","shell.execute_reply":"2022-03-16T18:53:02.184961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.environ[\"WANDB_API_KEY\"] = \"0\" ## to silence warning","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:53:02.187933Z","iopub.execute_input":"2022-03-16T18:53:02.188199Z","iopub.status.idle":"2022-03-16T18:53:02.19296Z","shell.execute_reply.started":"2022-03-16T18:53:02.188165Z","shell.execute_reply":"2022-03-16T18:53:02.192007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() \n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu) \nexcept ValueError: \n    strategy = tf.distribute.get_strategy() \n    print('Number of replicas:', strategy.num_replicas_in_sync) ","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:53:03.899801Z","iopub.execute_input":"2022-03-16T18:53:03.900145Z","iopub.status.idle":"2022-03-16T18:53:11.298433Z","shell.execute_reply.started":"2022-03-16T18:53:03.900109Z","shell.execute_reply":"2022-03-16T18:53:11.297076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reading csv files - train and test \ntrain = pd.read_csv('/kaggle/input/contradictory-my-dear-watson/train.csv')\ntest = pd.read_csv('/kaggle/input/contradictory-my-dear-watson/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:53:11.301519Z","iopub.execute_input":"2022-03-16T18:53:11.301771Z","iopub.status.idle":"2022-03-16T18:53:11.421938Z","shell.execute_reply.started":"2022-03-16T18:53:11.301743Z","shell.execute_reply":"2022-03-16T18:53:11.421069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#printing first 5 rows \ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:53:12.688884Z","iopub.execute_input":"2022-03-16T18:53:12.68953Z","iopub.status.idle":"2022-03-16T18:53:12.705019Z","shell.execute_reply.started":"2022-03-16T18:53:12.689477Z","shell.execute_reply":"2022-03-16T18:53:12.70426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe(include='all')","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:53:13.388655Z","iopub.execute_input":"2022-03-16T18:53:13.389297Z","iopub.status.idle":"2022-03-16T18:53:13.454426Z","shell.execute_reply.started":"2022-03-16T18:53:13.389256Z","shell.execute_reply":"2022-03-16T18:53:13.453476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#plotting missingno. bar and matrix to get null values\nimport missingno as msn\nmsn.bar(train)\nmsn.matrix(train)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:53:13.682544Z","iopub.execute_input":"2022-03-16T18:53:13.685895Z","iopub.status.idle":"2022-03-16T18:53:16.07207Z","shell.execute_reply.started":"2022-03-16T18:53:13.685663Z","shell.execute_reply":"2022-03-16T18:53:16.071334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we dont get any null values still reconfirming via isnull() function\ntrain.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:53:16.073882Z","iopub.execute_input":"2022-03-16T18:53:16.074785Z","iopub.status.idle":"2022-03-16T18:53:16.094363Z","shell.execute_reply.started":"2022-03-16T18:53:16.074738Z","shell.execute_reply":"2022-03-16T18:53:16.0937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dropping language axis as we already have lang_abv to distinguish languages\ntrain=train.drop('language',axis=1)\ntest=test.drop('language',axis=1)\ntrain.head()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:53:16.095688Z","iopub.execute_input":"2022-03-16T18:53:16.096076Z","iopub.status.idle":"2022-03-16T18:53:16.116105Z","shell.execute_reply.started":"2022-03-16T18:53:16.096046Z","shell.execute_reply":"2022-03-16T18:53:16.114977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#countplot for different lang_abv\nsns.countplot(x='lang_abv', data=train)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:53:16.118206Z","iopub.execute_input":"2022-03-16T18:53:16.118771Z","iopub.status.idle":"2022-03-16T18:53:16.415971Z","shell.execute_reply.started":"2022-03-16T18:53:16.118731Z","shell.execute_reply":"2022-03-16T18:53:16.414612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(9,9))\ntrain.groupby('lang_abv').size().plot(kind='pie', autopct='%1.1f%%')","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:53:16.417481Z","iopub.execute_input":"2022-03-16T18:53:16.417827Z","iopub.status.idle":"2022-03-16T18:53:16.694053Z","shell.execute_reply.started":"2022-03-16T18:53:16.417783Z","shell.execute_reply":"2022-03-16T18:53:16.693412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Checking class distribution for particular labels\ntrain.label.value_counts().plot(kind='bar')\nplt.xlabel(\"Classes\")\nplt.ylabel(\"no. of occurences\")\nplt.title(\"Train Classes distribution\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:53:16.695142Z","iopub.execute_input":"2022-03-16T18:53:16.695996Z","iopub.status.idle":"2022-03-16T18:53:16.880961Z","shell.execute_reply.started":"2022-03-16T18:53:16.695956Z","shell.execute_reply":"2022-03-16T18:53:16.880086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#distribution of languages and labels\nimport seaborn as sns\n\nfig, ax = plt.subplots(figsize = (12,5))\n\n#for maximum aesthetics\npalette = sns.cubehelix_palette(8, start=2, rot=0, dark=0, light=.95, reverse=True)\n\ngraph1 = sns.countplot(train['lang_abv'], hue = train['label'])#, palette = palette)\n\n#set title\ngraph1.set_title('Distribution of Languages and Labels')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:53:16.882458Z","iopub.execute_input":"2022-03-16T18:53:16.882964Z","iopub.status.idle":"2022-03-16T18:53:17.552008Z","shell.execute_reply.started":"2022-03-16T18:53:16.882922Z","shell.execute_reply":"2022-03-16T18:53:17.550784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Calling autotokenizer for pretrained model- \"joeddav/xlm-roberta-large-xnli\"\nfrom transformers import BertTokenizer, TFBertModel, TFAutoModel,AutoTokenizer\n\n#This model takes xlm-roberta-large and fine-tunes it on a combination of NLI data in 15 languages.\n#tokenizer = BertTokenizer.from_pretrained(model_name) \n\nmodel_name = \"joeddav/xlm-roberta-large-xnli\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:53:17.553278Z","iopub.execute_input":"2022-03-16T18:53:17.553634Z","iopub.status.idle":"2022-03-16T18:53:20.87989Z","shell.execute_reply.started":"2022-03-16T18:53:17.553605Z","shell.execute_reply":"2022-03-16T18:53:20.879185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A function to encode our premise sentences into tokens (word embedding)\ndef encode_premise_sentence(s):\n    tokens = []\n    tokens.append('[CLS]')\n    tokens+=list(tokenizer.tokenize(s))\n    return tokenizer.convert_tokens_to_ids(tokens)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:53:35.026674Z","iopub.execute_input":"2022-03-16T18:53:35.027494Z","iopub.status.idle":"2022-03-16T18:53:35.032917Z","shell.execute_reply.started":"2022-03-16T18:53:35.027449Z","shell.execute_reply":"2022-03-16T18:53:35.031774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A function to encode our hypothesis sentences into tokens (word embedding)\ndef encode_hypothesis_sentence(s):\n    tokens = []\n    tokens.append('[SEP]')\n    #[SEP] is for separating sentences for the next sentence prediction task\n    tokens+=list(tokenizer.tokenize(s))\n    tokens.append('[SEP]')\n    return tokenizer.convert_tokens_to_ids(tokens)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:53:36.590815Z","iopub.execute_input":"2022-03-16T18:53:36.59111Z","iopub.status.idle":"2022-03-16T18:53:36.596943Z","shell.execute_reply.started":"2022-03-16T18:53:36.591081Z","shell.execute_reply":"2022-03-16T18:53:36.595822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Tokenizing the premise and hypotheis sentences  for len(train) i.e #(rows)\ntokenized=[]\nfor each in range(len(train)):\n    pre=encode_premise_sentence(train['premise'][each])\n    hyp=encode_hypothesis_sentence(train['hypothesis'][each])\n    #Comibining both tokenized sentences to one \n    tokenized.append(pre+hyp)\ntrain['tokenized'] = tokenized\ntrain.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:53:38.996677Z","iopub.execute_input":"2022-03-16T18:53:38.997178Z","iopub.status.idle":"2022-03-16T18:53:44.592053Z","shell.execute_reply.started":"2022-03-16T18:53:38.997128Z","shell.execute_reply":"2022-03-16T18:53:44.591078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#adding padding in the tokenizer\nmask=[]\nfor each in range(len(train)):\n    padded_sequences = tokenizer(train['premise'][each],train['hypothesis'][each], padding=True,add_special_tokens = True)\n    mask.append(padded_sequences)\ntrain['masked'] = mask\ntrain.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:53:46.44029Z","iopub.execute_input":"2022-03-16T18:53:46.440978Z","iopub.status.idle":"2022-03-16T18:53:50.573639Z","shell.execute_reply.started":"2022-03-16T18:53:46.440934Z","shell.execute_reply":"2022-03-16T18:53:50.572582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Building tf model from pretrained joeddav/xlm-roberta-large-xnli\n#Appylying bert_encoder and optimizers\nmax_len=237 \n\ndef build_model():\n    bert_encoder = TFAutoModel.from_pretrained('joeddav/xlm-roberta-large-xnli')\n    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n    #input_type_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_type_ids\")\n    \n    embedding = bert_encoder([input_word_ids, input_mask])[0]\n    output = tf.keras.layers.Dense(3, activation='softmax')(embedding[:,0,:])\n    \n    model = tf.keras.Model(inputs=[input_word_ids, input_mask], outputs=output)\n    model.compile(tf.keras.optimizers.Adam(lr=1e-5), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:53:52.820641Z","iopub.execute_input":"2022-03-16T18:53:52.820972Z","iopub.status.idle":"2022-03-16T18:53:52.830154Z","shell.execute_reply.started":"2022-03-16T18:53:52.820936Z","shell.execute_reply":"2022-03-16T18:53:52.828951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def input_convert(data):\n    inputs   = {\n            'input_word_ids' :[],\n            'input_mask'     :[]  }\n    for each in data:\n        inputs['input_word_ids'].append(each['input_ids'])\n        inputs['input_mask'].append(each['attention_mask'])\n        \n    \n    inputs['input_word_ids']= tf.ragged.constant( inputs['input_word_ids']).to_tensor()\n    inputs['input_mask']= tf.ragged.constant( inputs['input_mask']).to_tensor()\n  \n    \n    return inputs","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:53:55.904161Z","iopub.execute_input":"2022-03-16T18:53:55.904942Z","iopub.status.idle":"2022-03-16T18:53:55.91139Z","shell.execute_reply.started":"2022-03-16T18:53:55.9049Z","shell.execute_reply":"2022-03-16T18:53:55.910421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_input= input_convert(train['masked'].values)\nfor key in train_input.keys():\n    train_input[key] = train_input[key][:,:max_len]    ","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:53:55.912899Z","iopub.execute_input":"2022-03-16T18:53:55.913546Z","iopub.status.idle":"2022-03-16T18:54:00.492045Z","shell.execute_reply.started":"2022-03-16T18:53:55.913508Z","shell.execute_reply":"2022-03-16T18:54:00.491382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#appylying the build_model and fitting on train data\nearly_stop = tf.keras.callbacks.EarlyStopping(patience=3,restore_best_weights=True)\nwith strategy.scope():\n    model = build_model()\n    model.summary()\n    model.fit(train_input, train['label'].values, epochs = 5, verbose = 1, batch_size = 128, validation_split = 0.1 ,callbacks=[early_stop])","metadata":{"execution":{"iopub.status.busy":"2022-03-16T18:54:31.930561Z","iopub.execute_input":"2022-03-16T18:54:31.931498Z","iopub.status.idle":"2022-03-16T19:02:51.059951Z","shell.execute_reply.started":"2022-03-16T18:54:31.931455Z","shell.execute_reply":"2022-03-16T19:02:51.058353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#applying tokenizer on test data\nmask=[]\nfor each in range(len(test)):\n    padded_sequences = tokenizer(test['premise'][each],test['hypothesis'][each], padding=True,add_special_tokens = True)\n    mask.append(padded_sequences)\ntest['masked'] = mask\ntest.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T19:02:51.061887Z","iopub.execute_input":"2022-03-16T19:02:51.062185Z","iopub.status.idle":"2022-03-16T19:02:52.974223Z","shell.execute_reply.started":"2022-03-16T19:02:51.062152Z","shell.execute_reply":"2022-03-16T19:02:52.973548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_input= input_convert(test['masked'].values)\nfor key in test_input.keys():\n    test_input[key] = test_input[key][:,:max_len]","metadata":{"execution":{"iopub.status.busy":"2022-03-16T19:05:42.393473Z","iopub.execute_input":"2022-03-16T19:05:42.39427Z","iopub.status.idle":"2022-03-16T19:05:44.393964Z","shell.execute_reply.started":"2022-03-16T19:05:42.394223Z","shell.execute_reply":"2022-03-16T19:05:44.392985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = [np.argmax(i) for i in model.predict(test_input)]","metadata":{"execution":{"iopub.status.busy":"2022-03-16T19:06:32.982959Z","iopub.execute_input":"2022-03-16T19:06:32.983246Z","iopub.status.idle":"2022-03-16T19:07:06.931819Z","shell.execute_reply.started":"2022-03-16T19:06:32.983217Z","shell.execute_reply":"2022-03-16T19:07:06.930674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2022-03-16T19:07:06.933783Z","iopub.execute_input":"2022-03-16T19:07:06.934076Z","iopub.status.idle":"2022-03-16T19:07:06.9558Z","shell.execute_reply.started":"2022-03-16T19:07:06.934044Z","shell.execute_reply":"2022-03-16T19:07:06.954713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating a new file 'Submission'\nsubmission = test['id'].copy().to_frame()\nsubmission['prediction'] = predictions\nsubmission.to_csv('/kaggle/submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T19:10:15.828829Z","iopub.execute_input":"2022-03-16T19:10:15.829249Z","iopub.status.idle":"2022-03-16T19:10:15.861209Z","shell.execute_reply.started":"2022-03-16T19:10:15.829202Z","shell.execute_reply":"2022-03-16T19:10:15.860163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2022-03-16T19:10:16.612069Z","iopub.execute_input":"2022-03-16T19:10:16.612462Z","iopub.status.idle":"2022-03-16T19:10:16.627696Z","shell.execute_reply.started":"2022-03-16T19:10:16.612426Z","shell.execute_reply":"2022-03-16T19:10:16.626795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T19:13:39.30897Z","iopub.execute_input":"2022-03-16T19:13:39.309358Z","iopub.status.idle":"2022-03-16T19:13:39.328815Z","shell.execute_reply.started":"2022-03-16T19:13:39.309316Z","shell.execute_reply":"2022-03-16T19:13:39.327927Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}